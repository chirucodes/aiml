PLAN ON 4 AUG 2022
****************************************************************

PRAVEEN: 

- Evaluating the model with test data
- Get the accuracy metrics
- Printing the metrics at the end
- Exploring Bleu, Cider and Meteor

****************************************************************

SATYAM: 

- Download all the datasets(Flickr8k, Flickr30k, COCO123K) and keep them in google drive and share with everyone
- Make sure that the downloaded datsets are in same format/structure
- Data massaging for train and test splitting 

****************************************************************
CHIRU:

DONE - Make the single google colab work for all the hyper parameters with conditions
- Share an excell sheet to record the metrics for different hyper parameters like with attention and without attention, optimizers, learning rate, train and test data split ratio, etc 
- Logic for updating the excell sheet if possible
- Exploring initial phase of deployment. where to host? UI?

****************************************************************
YASWANTH:

- transformers
- use hard attention

****************************************************************

PLAN ON 23 JUL 2022

****************************************************************

BACKLOG:

- list the alternate encoders and decoders and explore them - LSTM, GRU
- Conclude the best encoder and decoder approaches
- Explore glove / word2vec / etc
- Explore tokenization / lemmatization 
- Exploring different types of model evalution methods bleu, etc (1 week)

Deploymnets: (4 weeks)
- FastAPI + cloud deployment
- Exploring alternate deployment approaches:
---- Deploy to aws, azure, gcp, deta.sh, 
---- Deploy to mobile app
---- Deploy to telegram/ watsapp

****************************************************************
By 31 Jul 2022

DONE - Understand soft attention
- Understand hard attention
- Understand transformers
DONE - implemmentation of attention
- implemmentation of transformers 
DONE - Visualization of network architecture
- greedySearch
- ppt preparation

****************************************************************


PLAN ON 16 JUL 2022

****************************************************************
By 24 Jul 2022

YASWANTH:
DONE - Line by line code understanding
DONE - Data set 
DONE - Image feature extractor
DONE - Preprocessing the images
DONE - Feature vectors of the images using ResNet50
****************************************************************
By 24 Jul 2022

CHIRU / PRAVEEN:

ResNet50 
DONE - what and why?
DONE - Architecture
DONE - Importance of each layer
DONE - input and output of each layer
DONE - preprocess, etc
- Model parameters
- Compare it with InceptionV3
****************************************************************
By 24 Jul 2022

YASWANTH:

DONE - Text processor
DONE - Vocabulary of words
DONE - Feature vectors for words
- Understanding of GloVe, word2vec

****************************************************************
By 24 Jul 2022

SATYAM / PRAVEEN:

LSTM
DONE - what and why?
DONE - Architecture
DONE - Importance of each layer
DONE - input and output of each layer
DONE - Model parameters
DONE - compile, fit_generator, model.save

****************************************************************
By 24 Jul 2022

SATYAM:

DONE - Evaluationg the model - accuracy metrics - confusion matrix - Bleu Score
---- https://www.youtube.com/watch?v=9d4Oxx06r3Q


****************************************************************

By 24 Jul 2022

ALL:
DONE - Get 5 captions

Dobts to be clarified:

DONE - Padding - valid/same, when to use what?
DONE - stride m X n, why not only m?
DONE - what is activation is converting linear to non-linear why?
DONE - The relation between SVM and Activation function?
DONE - Batch1Normalization, Batch2Normalization

****************************************************************

By 30 Jul 2022

Dobts to be clarified:

- Why Input layer count is getting added
